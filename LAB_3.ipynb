{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/icampuzanov/SIS420-2_2023/blob/main/LAB_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4ezJirofDOK"
      },
      "source": [
        "# Ejercicion de programación - Regresión Logistica\n",
        "\n",
        "En este ejercicio se implementa regresion logistica y se aplica a dos diferentes datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIILrG1ifDOM"
      },
      "source": [
        "# se utiliza para el manejo de rutas y directorios.\n",
        "import os\n",
        "\n",
        "# Calculo cientifico y vectorial para python\n",
        "import numpy as np\n",
        "\n",
        "# Librerias para graficar\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# Modulo de optimización de scipy\n",
        "from scipy import optimize\n",
        "\n",
        "# le dice a matplotlib que incruste gráficos en el cuaderno\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "J6XcnwMsemRv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Carga de dataset con pandas\n",
        "data = pd.read_csv('/content/dataR2.csv')"
      ],
      "metadata": {
        "id": "ZtzlHjpUenIB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAbdicrSe8NA",
        "outputId": "559eb017-e2da-4cf3-8d05-7c9416aaf011"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Age        BMI  Glucose  Insulin      HOMA   Leptin  Adiponectin  \\\n",
            "0     48  23.500000       70    2.707  0.467409   8.8071     9.702400   \n",
            "1     83  20.690495       92    3.115  0.706897   8.8438     5.429285   \n",
            "2     82  23.124670       91    4.498  1.009651  17.9393    22.432040   \n",
            "3     68  21.367521       77    3.226  0.612725   9.8827     7.169560   \n",
            "4     86  21.111111       92    3.549  0.805386   6.6994     4.819240   \n",
            "..   ...        ...      ...      ...       ...      ...          ...   \n",
            "111   45  26.850000       92    3.330  0.755688  54.6800    12.100000   \n",
            "112   62  26.840000      100    4.530  1.117400  12.4500    21.420000   \n",
            "113   65  32.050000       97    5.730  1.370998  61.4800    22.540000   \n",
            "114   72  25.590000       82    2.820  0.570392  24.9600    33.750000   \n",
            "115   86  27.180000      138   19.910  6.777364  90.2800    14.110000   \n",
            "\n",
            "     Resistin    MCP.1  Classification  \n",
            "0     7.99585  417.114               1  \n",
            "1     4.06405  468.786               1  \n",
            "2     9.27715  554.697               1  \n",
            "3    12.76600  928.220               1  \n",
            "4    10.57635  773.920               1  \n",
            "..        ...      ...             ...  \n",
            "111  10.96000  268.230               2  \n",
            "112   7.32000  330.160               2  \n",
            "113  10.33000  314.050               2  \n",
            "114   3.27000  392.460               2  \n",
            "115   4.35000   90.090               2  \n",
            "\n",
            "[116 rows x 10 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFzWxw7SfDON"
      },
      "source": [
        "## 1 Regresion Logistica\n",
        "\n",
        "En esta parte del ejercicio, creará un modelo de regresión logística para predecir si un estudiante será admitido en una universidad. Suponga que es el administrador de un departamento universitario y desea determinar las posibilidades de admisión de cada solicitante en función de sus resultados en dos exámenes. Tiene datos históricos de solicitantes anteriores que puede usar como un conjunto de capacitación para la regresión logística. Para cada ejemplo de capacitación, se tiene las calificaciones del solicitante en dos exámenes y la decisión de admisión. Su tarea es crear un modelo de clasificación que calcule la probabilidad de admisión de un solicitante en función de los puntajes de esos dos exámenes.\n",
        "\n",
        "La siguiente celda cargará los datos y las etiquetas correspondientes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j4beWIbfDON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b44078-c5c3-4eac-dd98-23a1d37faf4f"
      },
      "source": [
        "X = data.iloc[:, :9]\n",
        "y = data.iloc[:, 9]\n",
        "m = y.size\n",
        "X.info()\n",
        "print('*'*30)\n",
        "print(y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 116 entries, 0 to 115\n",
            "Data columns (total 9 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   Age          116 non-null    int64  \n",
            " 1   BMI          116 non-null    float64\n",
            " 2   Glucose      116 non-null    int64  \n",
            " 3   Insulin      116 non-null    float64\n",
            " 4   HOMA         116 non-null    float64\n",
            " 5   Leptin       116 non-null    float64\n",
            " 6   Adiponectin  116 non-null    float64\n",
            " 7   Resistin     116 non-null    float64\n",
            " 8   MCP.1        116 non-null    float64\n",
            "dtypes: float64(7), int64(2)\n",
            "memory usage: 8.3 KB\n",
            "******************************\n",
            "0      1\n",
            "1      1\n",
            "2      1\n",
            "3      1\n",
            "4      1\n",
            "      ..\n",
            "111    2\n",
            "112    2\n",
            "113    2\n",
            "114    2\n",
            "115    2\n",
            "Name: Classification, Length: 116, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def  featureNormalize(X):\n",
        "    X_norm = X.copy()\n",
        "    mu = np.zeros(X.shape[1])\n",
        "    sigma = np.zeros(X.shape[1])\n",
        "\n",
        "    mu = np.mean(X, axis = 0)\n",
        "    sigma = np.std(X, axis = 0)\n",
        "    X_norm = (X - mu) / sigma\n",
        "\n",
        "    return X_norm, mu, sigma"
      ],
      "metadata": {
        "id": "8mLy4YXBqcQP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llama featureNormalize con los datos cargados\n",
        "X_norm, mu, sigma = featureNormalize(X)\n",
        "\n",
        "print(X)\n",
        "print('Media calculada:', mu)\n",
        "print('Desviación estandar calculada:', sigma)\n",
        "print(X_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0nEzQ4DqeFM",
        "outputId": "a847432e-dd05-48af-f3fc-be8feb95f28f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Age        BMI  Glucose  Insulin      HOMA   Leptin  Adiponectin  \\\n",
            "0     48  23.500000       70    2.707  0.467409   8.8071     9.702400   \n",
            "1     83  20.690495       92    3.115  0.706897   8.8438     5.429285   \n",
            "2     82  23.124670       91    4.498  1.009651  17.9393    22.432040   \n",
            "3     68  21.367521       77    3.226  0.612725   9.8827     7.169560   \n",
            "4     86  21.111111       92    3.549  0.805386   6.6994     4.819240   \n",
            "..   ...        ...      ...      ...       ...      ...          ...   \n",
            "111   45  26.850000       92    3.330  0.755688  54.6800    12.100000   \n",
            "112   62  26.840000      100    4.530  1.117400  12.4500    21.420000   \n",
            "113   65  32.050000       97    5.730  1.370998  61.4800    22.540000   \n",
            "114   72  25.590000       82    2.820  0.570392  24.9600    33.750000   \n",
            "115   86  27.180000      138   19.910  6.777364  90.2800    14.110000   \n",
            "\n",
            "     Resistin    MCP.1  \n",
            "0     7.99585  417.114  \n",
            "1     4.06405  468.786  \n",
            "2     9.27715  554.697  \n",
            "3    12.76600  928.220  \n",
            "4    10.57635  773.920  \n",
            "..        ...      ...  \n",
            "111  10.96000  268.230  \n",
            "112   7.32000  330.160  \n",
            "113  10.33000  314.050  \n",
            "114   3.27000  392.460  \n",
            "115   4.35000   90.090  \n",
            "\n",
            "[116 rows x 9 columns]\n",
            "Media calculada: Age             57.301724\n",
            "BMI             27.582111\n",
            "Glucose         97.793103\n",
            "Insulin         10.012086\n",
            "HOMA             2.694988\n",
            "Leptin          26.615080\n",
            "Adiponectin     10.180874\n",
            "Resistin        14.725966\n",
            "MCP.1          534.647000\n",
            "dtype: float64\n",
            "Desviación estandar calculada: Age             16.043164\n",
            "BMI              4.998450\n",
            "Glucose         22.427860\n",
            "Insulin         10.024278\n",
            "HOMA             3.626311\n",
            "Leptin          19.100428\n",
            "Adiponectin      6.813780\n",
            "Resistin        12.337122\n",
            "MCP.1          344.418433\n",
            "dtype: float64\n",
            "          Age       BMI   Glucose   Insulin      HOMA    Leptin  Adiponectin  \\\n",
            "0   -0.579794 -0.816675 -1.239222 -0.728739 -0.614282 -0.932334    -0.070222   \n",
            "1    1.601821 -1.378751 -0.258299 -0.688038 -0.548240 -0.930413    -0.697350   \n",
            "2    1.539489 -0.891764 -0.302887 -0.550073 -0.464752 -0.454219     1.797998   \n",
            "3    0.666843 -1.243303 -0.927110 -0.676965 -0.574210 -0.876021    -0.441945   \n",
            "4    1.788816 -1.294601 -0.258299 -0.644743 -0.521081 -1.042682    -0.786881   \n",
            "..        ...       ...       ...       ...       ...       ...          ...   \n",
            "111 -0.766789 -0.146468 -0.258299 -0.666590 -0.534786  1.469335     0.281654   \n",
            "112  0.292852 -0.148468  0.098400 -0.546881 -0.435039 -0.741611     1.649470   \n",
            "113  0.479848  0.893855 -0.035362 -0.427172 -0.365106  1.825348     1.813843   \n",
            "114  0.916171 -0.398546 -0.704173 -0.717467 -0.585883 -0.086651     3.459038   \n",
            "115  1.788816 -0.080447  1.792721  0.987394  1.125766  3.333167     0.576644   \n",
            "\n",
            "     Resistin     MCP.1  \n",
            "0   -0.545517 -0.341251  \n",
            "1   -0.864214 -0.191224  \n",
            "2   -0.441660  0.058214  \n",
            "3   -0.158867  1.142718  \n",
            "4   -0.336352  0.694716  \n",
            "..        ...       ...  \n",
            "111 -0.305255 -0.773527  \n",
            "112 -0.600299 -0.593717  \n",
            "113 -0.356320 -0.640491  \n",
            "114 -0.928577 -0.412832  \n",
            "115 -0.841036 -1.290747  \n",
            "\n",
            "[116 rows x 9 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-Xx5IVBfDOP"
      },
      "source": [
        "<a id=\"section1\"></a>\n",
        "### 1.2 Implementacion\n",
        "\n",
        "#### 1.2.1 Fución Sigmoidea\n",
        "\n",
        "La hipotesis para la regresión logistica se define como:\n",
        "\n",
        "$$ h_\\theta(x) = g(\\theta^T x)$$\n",
        "\n",
        "donde la función $g$ is la función sigmoidea. La función sigmoidea se define como:\n",
        "\n",
        "$$g(z) = \\frac{1}{1+e^{-z}}$$.\n",
        "\n",
        "Los resultados que debe generar la funcion sigmoidea para valores positivos amplios de `x`, deben ser cercanos a 1, mientras que para valores negativos grandes, la sigmoide debe generar valores cercanos 0. La evaluacion de `sigmoid(0)` debe dar un resultado exacto de 0.5. Esta funcion tambien debe poder trabajar con vectores y matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxz27db7fDOQ"
      },
      "source": [
        "def sigmoid(z):\n",
        "    # Calcula la sigmoide de una entrada z\n",
        "    # convierte la intrada a un arreglo numpy\n",
        "    z = np.array(z)\n",
        "\n",
        "    g = np.zeros(z.shape)\n",
        "\n",
        "    g = 1 / (1 + np.exp(-z))\n",
        "\n",
        "    return g"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzXMjefFfDOQ"
      },
      "source": [
        "Se calcula el valor de la sigmoide aplicando la funcion sigmoid con `z=0`, se debe obtener un resultado de 0.5. RE recomienda experimentar con otros valores de `z`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arfKRAAVfDOQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0e5626a-dd7f-4310-e691-feb9021c48a8"
      },
      "source": [
        "# Prueba la implementacion de la funcion sigmoid\n",
        "z = 0\n",
        "g = sigmoid(z)\n",
        "\n",
        "print('g(', z, ') = ', g)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "g( 0 ) =  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQ9Jf06yfDOR"
      },
      "source": [
        "<a id=\"section2\"></a>\n",
        "#### 1.2.2 Función de Costo y Gradiente\n",
        "\n",
        "Se implementa la funcion cost y gradient, para la regresión logistica. Antes de continuar es importante agregar el termino de intercepcion a X."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COMnlBxmfDOR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb9327df-7b44-4529-b500-c1861de39ce6"
      },
      "source": [
        "# Configurar la matriz adecuadamente, y agregar una columna de unos que corresponde al termino de intercepción.\n",
        "m, n = X.shape\n",
        "# Agraga el termino de intercepción a A\n",
        "X = np.concatenate([np.ones((m, 1)), X_norm], axis=1)\n",
        "\n",
        "print(X[5])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.         -0.51746179 -0.94582375 -0.25829943 -0.67696507 -0.5412941\n",
            " -1.03575583  0.51349997 -0.3573253  -0.0123019 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO9hT_XbfDOS"
      },
      "source": [
        "La funcion de costo en una regresión logistica es:\n",
        "\n",
        "$$ J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} \\left[ -y^{(i)} \\log\\left(h_\\theta\\left( x^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - h_\\theta\\left( x^{(i)} \\right) \\right) \\right]$$\n",
        "\n",
        "y el gradiente del costo es un vector de la misma longitud como $\\theta$ donde el elemento $j^{th}$ (para $j = 0, 1, \\cdots , n$) se define como:\n",
        "\n",
        "$$ \\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\theta \\left( x^{(i)} \\right) - y^{(i)} \\right) x_j^{(i)} $$\n",
        "\n",
        "Si bien este gradiente parece idéntico al gradiente de regresión lineal, la fórmula es diferente porque la regresión lineal y logística tienen diferentes definiciones de $h_\\theta(x)$.\n",
        "<a id=\"costFunction\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu1DP0y0fDOT"
      },
      "source": [
        "def calcularCosto(theta, X, y):\n",
        "    # Inicializar algunos valores utiles\n",
        "    m = y.size  # numero de ejemplos de entrenamiento\n",
        "\n",
        "    J = 0\n",
        "    h = sigmoid(X.dot(theta.T))\n",
        "    J = (1 / m) * np.sum(-y.dot(np.log(h)) - (1 - y).dot(np.log(1 - h)))\n",
        "\n",
        "    return J"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZhegpMZfDOT"
      },
      "source": [
        "def descensoGradiente(theta, X, y, alpha, num_iters):\n",
        "    # Inicializa algunos valores\n",
        "    m = y.shape[0] # numero de ejemplos de entrenamiento\n",
        "\n",
        "    # realiza una copia de theta, el cual será acutalizada por el descenso por el gradiente\n",
        "    theta = theta.copy()\n",
        "    J_history = []\n",
        "\n",
        "    for i in range(num_iters):\n",
        "        h = sigmoid(X.dot(theta.T))\n",
        "        theta = theta - (alpha / m) * (h - y).dot(X)\n",
        "\n",
        "        J_history.append(calcularCosto(theta, X, y))\n",
        "    return theta, J_history"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "SWXIkeQafDOT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "1f5de8aa-aa56-43bb-8cde-23b7d735156a"
      },
      "source": [
        "# Elegir algun valor para alpha (probar varias alternativas)\n",
        "alpha = 0.00015\n",
        "num_iters = 15000\n",
        "\n",
        "# inicializa theta y ejecuta el descenso por el gradiente\n",
        "theta = np.zeros(10)\n",
        "theta, J_history = descensoGradiente(theta, X, y, alpha, num_iters)\n",
        "\n",
        "# Grafica la convergencia del costo\n",
        "pyplot.plot(np.arange(len(J_history)), J_history, lw=2)\n",
        "pyplot.xlabel('Numero de iteraciones')\n",
        "pyplot.ylabel('Costo J')\n",
        "\n",
        "# Muestra los resultados del descenso por el gradiente\n",
        "print('theta calculado por el descenso por el gradiente: {:s}'.format(str(theta)))\n",
        "\n",
        "# verificar si clasifica o no a la clase diabetes\n",
        "\n",
        "\n",
        "#X_array = [1, 48, 23.5, 70, 2.707, 0.467408667, 8.8071, 9.7024, 7.99585, 417.114]\n",
        "X_array = [1, 64, 34.5297228, 95, 4.427, 1.037393667, 21.2117, 5.46262, 6.70188, 252.449]\n",
        "\n",
        "X_array[1:10] = (X_array[1:10] - mu) / sigma\n",
        "\n",
        "\n",
        "ClassVariable = sigmoid(np.dot(X_array, theta))\n",
        "\n",
        "\n",
        "print(f\"Usando el descenso por el gradiente {ClassVariable} \")\n",
        "\n",
        "\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "theta calculado por el descenso por el gradiente: [ 1.88795864 -0.05111142 -0.1480118   0.34205772  0.22291521  0.2263004\n",
            " -0.02642174 -0.01029663  0.19998768  0.06423315]\n",
            "Usando el descenso por el gradiente 0.7725124280920985 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear un modelo de regresión logística con un número máximo de iteraciones más alto\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Entrenar el modelo en el conjunto de entrenamiento\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calcular la exactitud del modelo en el conjunto de prueba\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Exactitud en el conjunto de prueba: {:.2f}%'.format(accuracy * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gniitYq_wRHw",
        "outputId": "70d7b7c1-f8b6-4c60-b3f4-68b81d321cf1"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exactitud en el conjunto de prueba: 87.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear un modelo de regresión logística\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Entrenar el modelo en el conjunto de entrenamiento\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calcular la exactitud del modelo en el conjunto de prueba\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Exactitud en el conjunto de prueba: {:.2f}%'.format(accuracy * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fruw-XYMwBgo",
        "outputId": "c93448a2-a216-4253-876d-23384cdc7922"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exactitud en el conjunto de prueba: 87.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr8Lfi-ZfDOW"
      },
      "source": [
        "<a id=\"section4\"></a>\n",
        "#### 1.2.4 Evaluación de la regresión logistica\n",
        "\n",
        "Después de aprender los parámetros, se puede usar el modelo para predecir si un estudiante en particular será admitido. Para un estudiante con una puntuación en el Examen 1 de 45 y una puntuación en el Examen 2 de 85, debe esperar ver una probabilidad de admisión de 0,776. Otra forma de evaluar la calidad de los parámetros que hemos encontrado es ver qué tan bien predice el modelo aprendido en nuestro conjunto de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjavk2fEfDOX"
      },
      "source": [
        "def predict(theta, X):\n",
        "    \"\"\"\n",
        "    Predecir si la etiqueta es 0 o 1 mediante regresión logística aprendida.\n",
        "    Calcula las predicciones para X usando un umbral en 0.5 (es decir, si sigmoide (theta.T * x)> = 0.5, predice 1)\n",
        "\n",
        "    Parametros\n",
        "    ----------\n",
        "    theta : array_like\n",
        "        Parametros para regresion logistica. Un vecto de la forma (n+1, ).\n",
        "\n",
        "    X : array_like\n",
        "        Datos utilizados para el calculo de las predicciones.\n",
        "        La fila es el numero de los puntos para calcular las predicciones,\n",
        "        y las columnas con el numero de caracteristicas.\n",
        "\n",
        "    Devuelve\n",
        "    -------\n",
        "    p : array_like\n",
        "        Predicciones y 0 o 1 para cada fila en X.\n",
        "    \"\"\"\n",
        "    m = X.shape[0] # Numero de ejemplo de entrenamiento\n",
        "\n",
        "    p = np.zeros(m)\n",
        "\n",
        "    p = np.round(sigmoid(X.dot(theta.T)))\n",
        "    return p"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2rxLT_lfDOX"
      },
      "source": [
        "Una vez entrenado el modelo se procede a realizar la prediccion y evaluación de los resultados de predecir cual es el valor que vota el modelo para todos los datos utilizados en el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R075_m5sfDOX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2bc98f3-c39b-4a5f-8c80-86fcf20b8b2b"
      },
      "source": [
        "#  Predice la probabilidad de ingreso para un estudiante con nota de 45 en el examen 1 y nota de 85 en el examen 2\n",
        "prob = sigmoid(np.dot([1, 48, 23.5, 70, 2.707, 0.467408667, 8.8071, 9.7024, 7.99585, 417.114], theta))\n",
        "print('Para una persona con esos sintomas, se predice una probabilidad de diabetes de: {:.3f}%'.format(prob))\n",
        "\n",
        "\n",
        "# Compute accuracy on our training set\n",
        "p = predict(theta, X)\n",
        "print('Precisión de entrenamiento: {:.2f} %'.format(np.mean(p == y) * 100))\n",
        "print('Precisión esperada (aproximadamente): 80.00 %')"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Para una persona con esos sintomas, se predice una probabilidad de diabetes de: 1.000%\n",
            "Precisión de entrenamiento: 44.83 %\n",
            "Precisión esperada (aproximadamente): 80.00 %\n"
          ]
        }
      ]
    }
  ]
}